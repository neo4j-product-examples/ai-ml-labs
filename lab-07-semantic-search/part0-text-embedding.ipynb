{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ae6874-7585-4a0b-848c-965f639def41",
   "metadata": {},
   "source": [
    "# Text Embedding with Vertex AI\n",
    "\n",
    "In this notebook, we generate 10K filings text embeddings with the Vertex AI [`textembedding-gecko`](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings) model.  Unstructured text from 10K filings has been extracted using a parser beforehand.\n",
    "\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Get 10K filings unstructured text from a Google storage bucket\n",
    "2. specifically select Item 1 from the 10K which describes the business of the company: who and what the company does, what subsidiaries it owns, and what markets it operates in. \n",
    "3. Chunk the text into natural sections using NLTK (to avoid input token limits)\n",
    "4. Save text with embeddings to csv to stage for loading into graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856d4a5-00e4-4a8c-a911-9ae1e8f95bfc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb3b8f-e03c-4f08-9ff4-27b21d1fc0d9",
   "metadata": {},
   "source": [
    "First, check to ensure you're using the `neo4j_genai` kernel with the following command. This kernel has the necessary runtime and dependencies for this notebook. If you see a different kernel, try changing the kernel to `neo4j_genai` in the upper right corner of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aad4e36-7048-4bbf-a71a-a5d1b24d0ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neo4j_genai'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.path.basename(sys.executable.replace(\"/bin/python\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f0c88-229f-406a-8e65-5a3c64199d32",
   "metadata": {},
   "source": [
    "Next import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e7aeea-5d5d-4cbc-a454-9708de3a3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from string import Template\n",
    "import pandas as pd\n",
    "\n",
    "# Vertexai and google cloud\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b0998-b1f5-43f6-a278-9242e1b2b71e",
   "metadata": {},
   "source": [
    "## Get 10K Filings from Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4286ddb9-950d-4bee-ba7b-c717e3ee1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "(storage_client\n",
    " .bucket('neo4j-datasets')\n",
    " .blob('form10k/form10k-clean.zip')\n",
    " .download_to_filename('form10k-clean.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09449433-e3b9-4946-84ba-05a1ab0c47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq -n 'form10k-clean.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64dbe14-2aaa-4df0-97cc-6e03d47dd655",
   "metadata": {},
   "source": [
    "## 10K Filings Exploration and Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fdbd4-69eb-496d-9b06-d10f85aa5527",
   "metadata": {},
   "source": [
    "Let's open one file to understand its contents.  It is actually a json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d86432-2679-4f0a-a33c-c16064769d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./form10k-clean/0000002488-22-000016.txt') as f:\n",
    "    f10_k = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f8c51-b2fc-4704-85c0-12cd3b5a8c1f",
   "metadata": {},
   "source": [
    "We are interested in Item 1 specifically. \n",
    "\n",
    "Item 1 describes the business of the company: who and what the company does, what subsidiaries it owns, and what markets it operates in. It may also include recent events, competition, regulations, and labor issues. (Some industries are heavily regulated, and have complex labor requirements, which have significant effects on the business.) Other topics in this section may include special operating costs, seasonal factors, or insurance matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76566ea2-d2da-4dae-b196-d66c9570c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f10_k['item1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63be173-75e7-4017-9d61-8fe683ea199e",
   "metadata": {},
   "source": [
    "This text has the ability to exceed token limits for `textembedding-gecko`.  Also the quality of embeddings can go down if the text gets to large. As such we should find some way to chunk the text up into seperate sections for embedding.\n",
    "\n",
    "Below is a way to do this with NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04061873-2b51-40b2-98ea-8cfd46e6fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True) #downloads the tokenizer model that will help us with context aware of text splitting\n",
    "\n",
    "text = f10_k['item1']\n",
    "\n",
    "text_splitter = NLTKTextSplitter()\n",
    "docs = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d48aca-8acd-4ea2-ae2b-e8e0e18f2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede16b2-a881-48b5-b8ea-f3e4de6f0022",
   "metadata": {},
   "source": [
    "## Getting 10K Text Embeddings with VertexAI\n",
    "\n",
    "Now that we understand our data and how to chunk it.  Lets Generate embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2609f8e-5d72-4ed3-bf8f-85e7adaf34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, you will need to set your project_id\n",
    "project_id = 'neo4jbusinessdev'\n",
    "location = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ff3f6-fba3-4d86-b153-a637575fdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the text ebmedding model\n",
    "\n",
    "EMBEDDING_MODEL = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56acd5-e781-4ce7-b25f-49abdd9de8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need a chunking utility to make things easier as we loop through files\n",
    "\n",
    "def chunks(xs, n=5):\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20c6ac-6793-4de6-aaac-f83bb2178d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting and calculating embeddings\n",
    "\n",
    "def create_text_embedding_entries(input_text:str, company_name:str):\n",
    "    text_splitter = NLTKTextSplitter()\n",
    "    docs = text_splitter.split_text(input_text)\n",
    "    res = []\n",
    "    seq_id = -1\n",
    "    for d in chunks(docs):\n",
    "        embeddings = EMBEDDING_MODEL.get_embeddings(d)\n",
    "        for i in range(len(d)):\n",
    "            seq_id += 1\n",
    "            res.append({'companyName': company_name, 'seqId': seq_id, 'contextId': company_name + str(seq_id), 'textEmbedding': embeddings[i].values, 'text': d[i]})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3006c7-fa97-4282-bb31-6352ab0ed6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names\n",
    "\n",
    "file_names = os.listdir('./form10k-clean/')\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8497e11-d4f5-4bb3-80de-8cc538bd16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Primary loop.  This could take 30 minutes to an hour.\n",
    "count = 0\n",
    "embedding_entries = []\n",
    "for file_name in file_names:\n",
    "    if '.txt' in file_name:\n",
    "        count+=1\n",
    "        if count%10 == 0:\n",
    "            print(f'Parsed {count} of {len(file_names)}')\n",
    "        with open('./form10k-clean/' + file_name) as f:\n",
    "            f10_k = json.load(f)\n",
    "        embedding_entries.extend(create_text_embedding_entries(f10_k['item1'], f10_k['companyName']))\n",
    "len(embedding_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446e651-9134-4634-a527-4f2745c7d623",
   "metadata": {},
   "source": [
    "## Save 10K Documents with Embeddings\n",
    "\n",
    "We will save these locally to use in graph loading, in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca3c83-fdc8-4d30-bacd-4c0b0328655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pd.DataFrame(embedding_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cd795-4097-415f-83d6-f4caa651218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d235274-9cc5-4ea2-8e04-79fbe38a8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf.to_csv('form10k-doc-embeddings-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47dab3-fce2-4cce-af98-bb7958dd9fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "neo4j_genai (Local)",
   "language": "python",
   "name": "local-neo4j_genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
